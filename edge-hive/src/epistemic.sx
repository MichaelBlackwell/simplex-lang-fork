// Edge Hive - Epistemic Belief System
// Implements grounded beliefs with provenance, evidence, and falsifiers
//
// From TASK-014: Belief Epistemics
// - GroundedBelief<T> with evidence links and falsification conditions
// - CalibratedConfidence with ECE (Expected Calibration Error) tracking
// - EpistemicSchedule for anti-confirmation bias learning
// - Skeptic specialist for adversarial belief validation
// - No-learn zones for safety-critical functions

// =============================================================================
// Evidence Types
// =============================================================================

fn EVIDENCE_OBSERVATION() -> i64 { 1 }      // Direct observation
fn EVIDENCE_INFERENCE() -> i64 { 2 }        // Inferred from other beliefs
fn EVIDENCE_USER_EXPLICIT() -> i64 { 3 }    // User explicitly stated
fn EVIDENCE_CLOUD_SYNC() -> i64 { 4 }       // Received from cloud hive
fn EVIDENCE_PEER_SYNC() -> i64 { 5 }        // Received from peer device
fn EVIDENCE_MODEL_OUTPUT() -> i64 { 6 }     // Generated by local/cloud model

// Confidence calibration buckets
fn CAL_BUCKET_0_10() -> i64 { 0 }
fn CAL_BUCKET_10_20() -> i64 { 1 }
fn CAL_BUCKET_20_30() -> i64 { 2 }
fn CAL_BUCKET_30_40() -> i64 { 3 }
fn CAL_BUCKET_40_50() -> i64 { 4 }
fn CAL_BUCKET_50_60() -> i64 { 5 }
fn CAL_BUCKET_60_70() -> i64 { 6 }
fn CAL_BUCKET_70_80() -> i64 { 7 }
fn CAL_BUCKET_80_90() -> i64 { 8 }
fn CAL_BUCKET_90_100() -> i64 { 9 }

// Falsification status
fn FALSIFIER_ACTIVE() -> i64 { 0 }          // Condition is being monitored
fn FALSIFIER_TRIGGERED() -> i64 { 1 }       // Falsification condition met
fn FALSIFIER_EXPIRED() -> i64 { 2 }         // No longer relevant

// =============================================================================
// EvidenceLink Structure
// =============================================================================
// Tracks the provenance of a belief
// Slot 0: evidence_type
// Slot 1: source_id (user, device, model, etc.)
// Slot 2: timestamp
// Slot 3: confidence_at_time (0-1000)
// Slot 4: supporting_belief_hashes (vec of belief hashes that support this)

fn evidence_link_new(evidence_type: i64, source_id: i64, confidence: i64) -> i64 {
    let link: i64 = vec_new();
    vec_push(link, evidence_type);      // Slot 0
    vec_push(link, source_id);          // Slot 1
    vec_push(link, time_now());         // Slot 2
    vec_push(link, confidence);         // Slot 3
    vec_push(link, vec_new());          // Slot 4: supporting beliefs
    link
}

fn evidence_type(link: i64) -> i64 { vec_get(link, 0) }
fn evidence_source(link: i64) -> i64 { vec_get(link, 1) }
fn evidence_timestamp(link: i64) -> i64 { vec_get(link, 2) }
fn evidence_confidence(link: i64) -> i64 { vec_get(link, 3) }
fn evidence_supporters(link: i64) -> i64 { vec_get(link, 4) }

fn evidence_add_supporter(link: i64, belief_hash: i64) -> i64 {
    let supporters: i64 = evidence_supporters(link);
    vec_push(supporters, belief_hash);
    0
}

fn evidence_strength(link: i64) -> i64 {
    // Compute evidence strength based on type and age
    let base_strength: i64 = 500;  // Default

    let etype: i64 = evidence_type(link);
    if etype == EVIDENCE_USER_EXPLICIT() {
        base_strength = 1000;  // User explicit is strongest
    } else if etype == EVIDENCE_OBSERVATION() {
        base_strength = 800;
    } else if etype == EVIDENCE_INFERENCE() {
        base_strength = 600;
    } else if etype == EVIDENCE_MODEL_OUTPUT() {
        base_strength = 500;
    } else if etype == EVIDENCE_CLOUD_SYNC() {
        base_strength = 700;
    } else if etype == EVIDENCE_PEER_SYNC() {
        base_strength = 600;
    }

    // Decay based on age
    let age: i64 = time_now() - evidence_timestamp(link);
    let decay_days: i64 = age / 86400;
    let decay_factor: i64 = 1000 - decay_days * 10;  // 1% decay per day
    if decay_factor < 100 {
        decay_factor = 100;  // Minimum 10% strength
    }

    // Number of supporters increases strength
    let num_supporters: i64 = vec_len(evidence_supporters(link));
    let support_boost: i64 = num_supporters * 50;
    if support_boost > 200 {
        support_boost = 200;  // Cap at 20% boost
    }

    let final_strength: i64 = (base_strength * decay_factor / 1000) + support_boost;
    if final_strength > 1000 {
        final_strength = 1000;
    }
    final_strength
}

// =============================================================================
// Falsifier Structure
// =============================================================================
// Defines conditions under which a belief should be reconsidered
// Slot 0: condition_type (time, counter, external)
// Slot 1: condition_value
// Slot 2: current_value
// Slot 3: status (ACTIVE, TRIGGERED, EXPIRED)
// Slot 4: created_at

fn FALSIFIER_TIME() -> i64 { 1 }      // Falsify after N seconds
fn FALSIFIER_COUNTER() -> i64 { 2 }   // Falsify after N contradictions
fn FALSIFIER_EXTERNAL() -> i64 { 3 }  // Falsify when external signal received

fn falsifier_new(condition_type: i64, condition_value: i64) -> i64 {
    let f: i64 = vec_new();
    vec_push(f, condition_type);     // Slot 0
    vec_push(f, condition_value);    // Slot 1
    vec_push(f, 0);                  // Slot 2: current value
    vec_push(f, FALSIFIER_ACTIVE()); // Slot 3: status
    vec_push(f, time_now());         // Slot 4: created_at
    f
}

fn falsifier_type(f: i64) -> i64 { vec_get(f, 0) }
fn falsifier_threshold(f: i64) -> i64 { vec_get(f, 1) }
fn falsifier_current(f: i64) -> i64 { vec_get(f, 2) }
fn falsifier_status(f: i64) -> i64 { vec_get(f, 3) }
fn falsifier_created(f: i64) -> i64 { vec_get(f, 4) }

fn falsifier_increment(f: i64) -> i64 {
    let current: i64 = falsifier_current(f);
    vec_set(f, 2, current + 1);

    // Check if threshold reached
    if current + 1 >= falsifier_threshold(f) {
        vec_set(f, 3, FALSIFIER_TRIGGERED());
        return 1;  // Triggered
    }
    0
}

fn falsifier_check_time(f: i64) -> i64 {
    if falsifier_type(f) != FALSIFIER_TIME() {
        return 0;
    }
    let created: i64 = falsifier_created(f);
    let threshold: i64 = falsifier_threshold(f);
    if time_now() - created >= threshold {
        vec_set(f, 3, FALSIFIER_TRIGGERED());
        return 1;
    }
    0
}

fn falsifier_is_triggered(f: i64) -> i64 {
    // Check time-based first
    if falsifier_type(f) == FALSIFIER_TIME() {
        falsifier_check_time(f);
    }
    if falsifier_status(f) == FALSIFIER_TRIGGERED() { 1 } else { 0 }
}

// =============================================================================
// GroundedBelief Structure
// =============================================================================
// A belief with full epistemic grounding
// Slot 0: value
// Slot 1: belief_type
// Slot 2: key_hash
// Slot 3: confidence (calibrated, 0-1000)
// Slot 4: evidence_links (vec of EvidenceLink)
// Slot 5: falsifiers (vec of Falsifier)
// Slot 6: created_at
// Slot 7: last_updated
// Slot 8: update_count
// Slot 9: no_learn_zone (1 if protected from learning)

fn grounded_belief_new(belief_type: i64, key_hash: i64, value: i64) -> i64 {
    let b: i64 = vec_new();
    vec_push(b, value);           // Slot 0
    vec_push(b, belief_type);     // Slot 1
    vec_push(b, key_hash);        // Slot 2
    vec_push(b, 500);             // Slot 3: default 50% confidence
    vec_push(b, vec_new());       // Slot 4: evidence links
    vec_push(b, vec_new());       // Slot 5: falsifiers
    vec_push(b, time_now());      // Slot 6: created_at
    vec_push(b, time_now());      // Slot 7: last_updated
    vec_push(b, 0);               // Slot 8: update count
    vec_push(b, 0);               // Slot 9: not in no-learn zone
    b
}

// Accessors
fn grounded_value(b: i64) -> i64 { vec_get(b, 0) }
fn grounded_belief_type(b: i64) -> i64 { vec_get(b, 1) }
fn grounded_key_hash(b: i64) -> i64 { vec_get(b, 2) }
fn grounded_confidence(b: i64) -> i64 { vec_get(b, 3) }
fn grounded_evidence(b: i64) -> i64 { vec_get(b, 4) }
fn grounded_falsifiers(b: i64) -> i64 { vec_get(b, 5) }
fn grounded_created(b: i64) -> i64 { vec_get(b, 6) }
fn grounded_last_updated(b: i64) -> i64 { vec_get(b, 7) }
fn grounded_update_count(b: i64) -> i64 { vec_get(b, 8) }
fn grounded_is_no_learn(b: i64) -> i64 { vec_get(b, 9) }

fn grounded_set_value(b: i64, value: i64) -> i64 {
    vec_set(b, 0, value);
    vec_set(b, 7, time_now());
    let count: i64 = grounded_update_count(b);
    vec_set(b, 8, count + 1);
    0
}

fn grounded_set_confidence(b: i64, confidence: i64) -> i64 {
    let capped: i64 = confidence;
    if capped > 1000 { capped = 1000; }
    if capped < 0 { capped = 0; }
    vec_set(b, 3, capped);
    0
}

fn grounded_set_no_learn(b: i64, protected: i64) -> i64 {
    vec_set(b, 9, protected);
    0
}

fn grounded_add_evidence(b: i64, evidence: i64) -> i64 {
    // Check no-learn zone
    if grounded_is_no_learn(b) == 1 {
        return 0;  // Cannot modify evidence in no-learn zone
    }

    let links: i64 = grounded_evidence(b);
    vec_push(links, evidence);

    // Recalculate confidence based on all evidence
    grounded_recalculate_confidence(b);
    0
}

fn grounded_add_falsifier(b: i64, falsifier: i64) -> i64 {
    let falsifiers: i64 = grounded_falsifiers(b);
    vec_push(falsifiers, falsifier);
    0
}

fn grounded_recalculate_confidence(b: i64) -> i64 {
    let links: i64 = grounded_evidence(b);
    let len: i64 = vec_len(links);

    if len == 0 {
        grounded_set_confidence(b, 500);  // Default
        return 500;
    }

    // Aggregate evidence strength
    let total_strength: i64 = 0;
    let i: i64 = 0;
    while i < len {
        let link: i64 = vec_get(links, i);
        total_strength = total_strength + evidence_strength(link);
        i = i + 1;
    }

    // Average with diminishing returns
    let avg: i64 = total_strength / len;
    // Boost for multiple sources
    let source_boost: i64 = 0;
    if len > 1 { source_boost = 50; }
    if len > 3 { source_boost = 100; }
    if len > 5 { source_boost = 150; }

    let final_conf: i64 = avg + source_boost;
    if final_conf > 1000 { final_conf = 1000; }

    grounded_set_confidence(b, final_conf);
    final_conf
}

fn grounded_check_falsifiers(b: i64) -> i64 {
    // Returns 1 if any falsifier has triggered
    let falsifiers: i64 = grounded_falsifiers(b);
    let len: i64 = vec_len(falsifiers);
    let i: i64 = 0;
    while i < len {
        let f: i64 = vec_get(falsifiers, i);
        if falsifier_is_triggered(f) == 1 {
            return 1;
        }
        i = i + 1;
    }
    0
}

fn grounded_record_contradiction(b: i64) -> i64 {
    // Record a contradiction - may trigger counter-based falsifier
    let falsifiers: i64 = grounded_falsifiers(b);
    let len: i64 = vec_len(falsifiers);
    let i: i64 = 0;
    while i < len {
        let f: i64 = vec_get(falsifiers, i);
        if falsifier_type(f) == FALSIFIER_COUNTER() {
            if falsifier_increment(f) == 1 {
                return 1;  // Falsifier triggered
            }
        }
        i = i + 1;
    }
    0
}

// =============================================================================
// CalibratedConfidence Structure
// =============================================================================
// Tracks prediction accuracy to calibrate future confidence scores
// Uses 10 buckets (0-10%, 10-20%, ..., 90-100%)
// Slot 0-9: bucket counts [predictions, correct] pairs

fn calibrated_confidence_new() -> i64 {
    let cc: i64 = vec_new();
    let i: i64 = 0;
    while i < 10 {
        let bucket: i64 = vec_new();
        vec_push(bucket, 0);  // predictions
        vec_push(bucket, 0);  // correct
        vec_push(cc, bucket);
        i = i + 1;
    }
    cc
}

fn calibrated_bucket_for(confidence: i64) -> i64 {
    // Map 0-1000 confidence to bucket 0-9
    let bucket: i64 = confidence / 100;
    if bucket > 9 { bucket = 9; }
    bucket
}

fn calibrated_record(cc: i64, confidence: i64, was_correct: i64) -> i64 {
    let bucket_idx: i64 = calibrated_bucket_for(confidence);
    let bucket: i64 = vec_get(cc, bucket_idx);

    let predictions: i64 = vec_get(bucket, 0);
    let correct: i64 = vec_get(bucket, 1);

    vec_set(bucket, 0, predictions + 1);
    if was_correct == 1 {
        vec_set(bucket, 1, correct + 1);
    }
    0
}

fn calibrated_accuracy(cc: i64, bucket_idx: i64) -> i64 {
    // Returns actual accuracy for bucket (0-1000)
    let bucket: i64 = vec_get(cc, bucket_idx);
    let predictions: i64 = vec_get(bucket, 0);
    let correct: i64 = vec_get(bucket, 1);

    if predictions == 0 {
        // No data - assume calibrated
        return bucket_idx * 100 + 50;
    }

    correct * 1000 / predictions
}

fn calibrated_ece(cc: i64) -> i64 {
    // Compute Expected Calibration Error (lower is better)
    // ECE = sum(|accuracy - confidence| * count) / total
    let total_predictions: i64 = 0;
    let total_error: i64 = 0;

    let i: i64 = 0;
    while i < 10 {
        let bucket: i64 = vec_get(cc, i);
        let predictions: i64 = vec_get(bucket, 0);
        let correct: i64 = vec_get(bucket, 1);

        if predictions > 0 {
            let expected_accuracy: i64 = i * 100 + 50;  // Bucket midpoint
            let actual_accuracy: i64 = correct * 1000 / predictions;
            let error: i64 = expected_accuracy - actual_accuracy;
            if error < 0 { error = 0 - error; }

            total_error = total_error + error * predictions;
            total_predictions = total_predictions + predictions;
        }
        i = i + 1;
    }

    if total_predictions == 0 {
        return 0;  // No data
    }

    total_error / total_predictions
}

fn calibrated_adjust(cc: i64, raw_confidence: i64) -> i64 {
    // Adjust confidence based on historical calibration
    let bucket_idx: i64 = calibrated_bucket_for(raw_confidence);
    let actual_accuracy: i64 = calibrated_accuracy(cc, bucket_idx);

    // Blend raw with historical accuracy
    let adjusted: i64 = (raw_confidence + actual_accuracy) / 2;
    adjusted
}

// =============================================================================
// EpistemicSchedule Structure
// =============================================================================
// Anti-confirmation bias learning schedule
// Uses dissent windows to challenge high-confidence beliefs
// Slot 0: current_phase (explore, exploit, dissent)
// Slot 1: phase_start_time
// Slot 2: explore_duration
// Slot 3: exploit_duration
// Slot 4: dissent_duration
// Slot 5: dissent_threshold (confidence above which triggers skeptic)

fn PHASE_EXPLORE() -> i64 { 0 }
fn PHASE_EXPLOIT() -> i64 { 1 }
fn PHASE_DISSENT() -> i64 { 2 }

fn epistemic_schedule_new() -> i64 {
    let s: i64 = vec_new();
    vec_push(s, PHASE_EXPLORE());    // Slot 0: start in explore
    vec_push(s, time_now());         // Slot 1: phase start
    vec_push(s, 3600);               // Slot 2: 1 hour explore
    vec_push(s, 7200);               // Slot 3: 2 hours exploit
    vec_push(s, 1800);               // Slot 4: 30 min dissent
    vec_push(s, 800);                // Slot 5: challenge beliefs >80%
    s
}

fn schedule_phase(s: i64) -> i64 { vec_get(s, 0) }
fn schedule_phase_start(s: i64) -> i64 { vec_get(s, 1) }
fn schedule_explore_duration(s: i64) -> i64 { vec_get(s, 2) }
fn schedule_exploit_duration(s: i64) -> i64 { vec_get(s, 3) }
fn schedule_dissent_duration(s: i64) -> i64 { vec_get(s, 4) }
fn schedule_dissent_threshold(s: i64) -> i64 { vec_get(s, 5) }

fn schedule_update(s: i64) -> i64 {
    let current_phase: i64 = schedule_phase(s);
    let phase_start: i64 = schedule_phase_start(s);
    let elapsed: i64 = time_now() - phase_start;

    let duration: i64 = 0;
    let next_phase: i64 = current_phase;

    if current_phase == PHASE_EXPLORE() {
        duration = schedule_explore_duration(s);
        next_phase = PHASE_EXPLOIT();
    } else if current_phase == PHASE_EXPLOIT() {
        duration = schedule_exploit_duration(s);
        next_phase = PHASE_DISSENT();
    } else {
        duration = schedule_dissent_duration(s);
        next_phase = PHASE_EXPLORE();
    }

    if elapsed >= duration {
        vec_set(s, 0, next_phase);
        vec_set(s, 1, time_now());
        return next_phase;
    }

    current_phase
}

fn schedule_should_challenge(s: i64, confidence: i64) -> i64 {
    schedule_update(s);
    let phase: i64 = schedule_phase(s);

    // During dissent phase, challenge high-confidence beliefs
    if phase == PHASE_DISSENT() {
        if confidence >= schedule_dissent_threshold(s) {
            return 1;
        }
    }

    // During explore phase, be more skeptical overall
    if phase == PHASE_EXPLORE() {
        if confidence >= 900 {  // Only very high confidence
            return 1;
        }
    }

    0
}

fn schedule_learning_rate(s: i64) -> i64 {
    // Returns learning rate multiplier (0-1000)
    schedule_update(s);
    let phase: i64 = schedule_phase(s);

    if phase == PHASE_EXPLORE() {
        return 1000;  // Full learning in explore
    }
    if phase == PHASE_EXPLOIT() {
        return 500;   // Moderate learning in exploit
    }
    // Dissent phase
    return 200;       // Reduced learning during dissent
}

// =============================================================================
// Skeptic Specialist
// =============================================================================
// Adversarial validator for high-confidence beliefs
// Slot 0: challenges_issued
// Slot 1: challenges_upheld (belief remained)
// Slot 2: challenges_rejected (belief revised)
// Slot 3: calibration tracker

fn skeptic_new() -> i64 {
    let sk: i64 = vec_new();
    vec_push(sk, 0);                          // Slot 0: issued
    vec_push(sk, 0);                          // Slot 1: upheld
    vec_push(sk, 0);                          // Slot 2: rejected
    vec_push(sk, calibrated_confidence_new()); // Slot 3: calibration
    sk
}

fn skeptic_challenges_issued(sk: i64) -> i64 { vec_get(sk, 0) }
fn skeptic_challenges_upheld(sk: i64) -> i64 { vec_get(sk, 1) }
fn skeptic_challenges_rejected(sk: i64) -> i64 { vec_get(sk, 2) }
fn skeptic_calibration(sk: i64) -> i64 { vec_get(sk, 3) }

fn skeptic_challenge(sk: i64, belief: i64) -> i64 {
    // Challenge a belief, returns 1 if belief should be reconsidered
    let issued: i64 = skeptic_challenges_issued(sk);
    vec_set(sk, 0, issued + 1);

    let confidence: i64 = grounded_confidence(belief);
    let evidence: i64 = grounded_evidence(belief);
    let num_sources: i64 = vec_len(evidence);

    // Challenge criteria:
    // 1. Very high confidence but few sources
    if confidence > 900 && num_sources < 2 {
        return 1;  // Suspiciously confident
    }

    // 2. Check for stale evidence
    let has_recent: i64 = 0;
    let i: i64 = 0;
    while i < num_sources {
        let link: i64 = vec_get(evidence, i);
        let age: i64 = time_now() - evidence_timestamp(link);
        if age < 86400 {  // Less than 1 day old
            has_recent = 1;
            i = num_sources;  // Break
        }
        i = i + 1;
    }
    if confidence > 800 && has_recent == 0 {
        return 1;  // High confidence with only stale evidence
    }

    // 3. Check falsifiers
    if grounded_check_falsifiers(belief) == 1 {
        return 1;  // Falsification condition met
    }

    // 4. Random challenge (5% of high-confidence beliefs)
    if confidence > 700 {
        let random: i64 = time_now() % 100;
        if random < 5 {
            return 1;  // Random audit
        }
    }

    0  // Belief passes challenge
}

fn skeptic_record_outcome(sk: i64, was_upheld: i64, original_confidence: i64) -> i64 {
    let cal: i64 = skeptic_calibration(sk);
    calibrated_record(cal, original_confidence, was_upheld);

    if was_upheld == 1 {
        let upheld: i64 = skeptic_challenges_upheld(sk);
        vec_set(sk, 1, upheld + 1);
    } else {
        let rejected: i64 = skeptic_challenges_rejected(sk);
        vec_set(sk, 2, rejected + 1);
    }
    0
}

fn skeptic_effectiveness(sk: i64) -> i64 {
    // Returns skeptic effectiveness (0-1000)
    // Good skeptics catch overconfident beliefs (rejected / total challenges)
    let issued: i64 = skeptic_challenges_issued(sk);
    if issued == 0 {
        return 500;  // No data
    }

    let rejected: i64 = skeptic_challenges_rejected(sk);

    // We want some rejections (catches overconfidence) but not too many
    // (would mean we're too skeptical)
    let rejection_rate: i64 = rejected * 1000 / issued;

    // Ideal is 10-30% rejection rate
    if rejection_rate >= 100 && rejection_rate <= 300 {
        return 1000;  // Optimal
    }
    if rejection_rate < 100 {
        return 500 + rejection_rate * 5;  // Too lenient
    }
    // rejection_rate > 300
    return 1000 - (rejection_rate - 300) * 2;  // Too harsh
}

fn skeptic_print_stats(sk: i64) -> i64 {
    println(string_from("Skeptic Stats:"));

    print(string_from("  Challenges issued: "));
    print_i64(skeptic_challenges_issued(sk));
    println(string_from(""));

    print(string_from("  Beliefs upheld: "));
    print_i64(skeptic_challenges_upheld(sk));
    println(string_from(""));

    print(string_from("  Beliefs rejected: "));
    print_i64(skeptic_challenges_rejected(sk));
    println(string_from(""));

    print(string_from("  Effectiveness: "));
    print_i64(skeptic_effectiveness(sk));
    print(string_from("/1000"));
    println(string_from(""));

    let cal: i64 = skeptic_calibration(sk);
    print(string_from("  Calibration ECE: "));
    print_i64(calibrated_ece(cal));
    println(string_from(""));

    0
}

// =============================================================================
// EpistemicMonitors Structure
// =============================================================================
// Monitors epistemic health of the belief store
// Slot 0: skeptic
// Slot 1: schedule
// Slot 2: global_calibration
// Slot 3: beliefs_challenged_count
// Slot 4: confirmation_bias_score (0-1000, lower is better)

fn epistemic_monitors_new() -> i64 {
    let m: i64 = vec_new();
    vec_push(m, skeptic_new());                // Slot 0
    vec_push(m, epistemic_schedule_new());     // Slot 1
    vec_push(m, calibrated_confidence_new());  // Slot 2
    vec_push(m, 0);                            // Slot 3
    vec_push(m, 500);                          // Slot 4: neutral start
    m
}

fn monitors_skeptic(m: i64) -> i64 { vec_get(m, 0) }
fn monitors_schedule(m: i64) -> i64 { vec_get(m, 1) }
fn monitors_calibration(m: i64) -> i64 { vec_get(m, 2) }
fn monitors_challenged_count(m: i64) -> i64 { vec_get(m, 3) }
fn monitors_bias_score(m: i64) -> i64 { vec_get(m, 4) }

fn monitors_process_belief(m: i64, belief: i64) -> i64 {
    let schedule: i64 = monitors_schedule(m);
    let skeptic: i64 = monitors_skeptic(m);
    let confidence: i64 = grounded_confidence(belief);

    // Check if we should challenge this belief
    if schedule_should_challenge(schedule, confidence) == 1 {
        let challenged: i64 = monitors_challenged_count(m);
        vec_set(m, 3, challenged + 1);

        let should_revise: i64 = skeptic_challenge(skeptic, belief);
        return should_revise;
    }

    0
}

fn monitors_record_outcome(m: i64, prediction_confidence: i64, was_correct: i64) -> i64 {
    let cal: i64 = monitors_calibration(m);
    calibrated_record(cal, prediction_confidence, was_correct);

    // Update confirmation bias score
    // If high-confidence predictions are wrong, increase bias score
    if prediction_confidence > 800 && was_correct == 0 {
        let bias: i64 = monitors_bias_score(m);
        bias = bias + 50;
        if bias > 1000 { bias = 1000; }
        vec_set(m, 4, bias);
    } else if was_correct == 1 {
        // Correct predictions reduce bias score slightly
        let bias: i64 = monitors_bias_score(m);
        bias = bias - 10;
        if bias < 0 { bias = 0; }
        vec_set(m, 4, bias);
    }

    0
}

fn monitors_health_score(m: i64) -> i64 {
    // Overall epistemic health (0-1000)
    let cal: i64 = monitors_calibration(m);
    let ece: i64 = calibrated_ece(cal);
    let bias: i64 = monitors_bias_score(m);
    let skeptic: i64 = monitors_skeptic(m);
    let effectiveness: i64 = skeptic_effectiveness(skeptic);

    // Lower ECE is better, lower bias is better, higher effectiveness is better
    let ece_score: i64 = 1000 - ece;
    let bias_score: i64 = 1000 - bias;

    (ece_score + bias_score + effectiveness) / 3
}

fn monitors_print_health(m: i64) -> i64 {
    println(string_from("Epistemic Health:"));

    let schedule: i64 = monitors_schedule(m);
    let phase: i64 = schedule_phase(schedule);
    print(string_from("  Current phase: "));
    if phase == PHASE_EXPLORE() { println(string_from("explore")); }
    else if phase == PHASE_EXPLOIT() { println(string_from("exploit")); }
    else { println(string_from("dissent")); }

    print(string_from("  Learning rate: "));
    print_i64(schedule_learning_rate(schedule));
    print(string_from("/1000"));
    println(string_from(""));

    let cal: i64 = monitors_calibration(m);
    print(string_from("  Calibration ECE: "));
    print_i64(calibrated_ece(cal));
    println(string_from(""));

    print(string_from("  Confirmation bias: "));
    print_i64(monitors_bias_score(m));
    print(string_from("/1000"));
    println(string_from(""));

    print(string_from("  Overall health: "));
    print_i64(monitors_health_score(m));
    print(string_from("/1000"));
    println(string_from(""));

    0
}

// =============================================================================
// No-Learn Zone Management
// =============================================================================
// Protects safety-critical beliefs from learning modifications

fn NO_LEARN_PERMISSION() -> i64 { 1 }    // Permission-related beliefs
fn NO_LEARN_SECURITY() -> i64 { 2 }      // Security settings
fn NO_LEARN_IDENTITY() -> i64 { 3 }      // User identity
fn NO_LEARN_AUDIT() -> i64 { 4 }         // Audit log entries

fn is_no_learn_type(belief_type: i64) -> i64 {
    if belief_type == NO_LEARN_PERMISSION() { return 1; }
    if belief_type == NO_LEARN_SECURITY() { return 1; }
    if belief_type == NO_LEARN_IDENTITY() { return 1; }
    if belief_type == NO_LEARN_AUDIT() { return 1; }
    0
}

fn mark_no_learn_zone(belief: i64, zone_type: i64) -> i64 {
    // Mark a belief as protected from learning
    grounded_set_no_learn(belief, 1);

    // Add a falsifier that will NEVER trigger (protection marker)
    let protection_marker: i64 = falsifier_new(FALSIFIER_COUNTER(), 999999999);
    grounded_add_falsifier(belief, protection_marker);

    // Set confidence to maximum (protected beliefs are certain)
    grounded_set_confidence(belief, 1000);

    // Add special evidence marker
    let evidence: i64 = evidence_link_new(EVIDENCE_USER_EXPLICIT(), zone_type, 1000);
    // Directly add without recalculating (no-learn zone)
    let links: i64 = grounded_evidence(belief);
    vec_push(links, evidence);

    0
}

// =============================================================================
// Integration with BeliefStore
// =============================================================================

fn upgrade_to_grounded(belief_store: i64, monitors: i64) -> i64 {
    // Upgrade a basic BeliefStore to use GroundedBelief<T>
    // Returns count of upgraded beliefs
    let beliefs: i64 = belief_store_beliefs(belief_store);
    let len: i64 = vec_len(beliefs);
    let upgraded: i64 = 0;

    let i: i64 = 0;
    while i < len {
        let entry: i64 = vec_get(beliefs, i);
        let belief_type: i64 = belief_get_type(entry);
        let key_hash: i64 = belief_get_key_hash(entry);
        let value: i64 = belief_get_value(entry);
        let confidence: i64 = belief_get_confidence(entry);

        // Create grounded version
        let grounded: i64 = grounded_belief_new(belief_type, key_hash, value);
        grounded_set_confidence(grounded, confidence);

        // Add default evidence based on source
        let evidence: i64 = evidence_link_new(EVIDENCE_OBSERVATION(), 0, confidence);
        grounded_add_evidence(grounded, evidence);

        // Add time-based falsifier (re-evaluate after 1 week)
        let time_falsifier: i64 = falsifier_new(FALSIFIER_TIME(), 604800);
        grounded_add_falsifier(grounded, time_falsifier);

        // Add counter falsifier (re-evaluate after 3 contradictions)
        let counter_falsifier: i64 = falsifier_new(FALSIFIER_COUNTER(), 3);
        grounded_add_falsifier(grounded, counter_falsifier);

        // Check if this is a no-learn type
        if is_no_learn_type(belief_type) == 1 {
            mark_no_learn_zone(grounded, belief_type);
        }

        // Replace in store (simplified - would need proper replacement)
        vec_set(beliefs, i, grounded);
        upgraded = upgraded + 1;
        i = i + 1;
    }

    upgraded
}

// =============================================================================
// Extern Declarations
// =============================================================================

// From beliefs.sx
extern fn belief_store_beliefs(store: i64) -> i64;
extern fn belief_get_type(entry: i64) -> i64;
extern fn belief_get_key_hash(entry: i64) -> i64;
extern fn belief_get_value(entry: i64) -> i64;
extern fn belief_get_confidence(entry: i64) -> i64;

// From runtime
extern fn vec_new() -> i64;
extern fn vec_push(v: i64, val: i64) -> i64;
extern fn vec_get(v: i64, idx: i64) -> i64;
extern fn vec_set(v: i64, idx: i64, val: i64) -> i64;
extern fn vec_len(v: i64) -> i64;
extern fn string_from(s: &str) -> i64;
extern fn print(s: i64) -> i64;
extern fn println(s: i64) -> i64;
extern fn print_i64(n: i64) -> i64;
extern fn time_now() -> i64;
