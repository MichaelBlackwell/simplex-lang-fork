{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
{"text": "Generate documentation for this function:\n\n```python\ndef process_batch(items, batch_size=100, retry=3):\n    results = []\n    for i in range(0, len(items), batch_size):\n        batch = items[i:i+batch_size]\n        for attempt in range(retry):\n            try:\n                result = api.send(batch)\n                results.extend(result)\n                break\n            except APIError as e:\n                if attempt == retry - 1:\n                    raise\n                time.sleep(2 ** attempt)\n    return results\n```\n\nAssistant: \"\"\"\nProcess items in batches with retry logic.\n\nArgs:\n    items: List of items to process\n    batch_size: Number of items per batch (default: 100)\n    retry: Number of retry attempts on failure (default: 3)\n\nReturns:\n    List of processed results from all batches\n\nRaises:\n    APIError: If all retry attempts fail for a batch\n\nExample:\n    >>> results = process_batch(my_items, batch_size=50)\n    >>> print(f\"Processed {len(results)} items\")\n\nNotes:\n    - Uses exponential backoff for retries (2^attempt seconds)\n    - Batching reduces API load and improves throughput\n\"\"\"\n[confidence: 0.93]"}
