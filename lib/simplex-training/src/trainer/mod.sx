// simplex-training::trainer - Meta and Specialist Trainers
//
// Implements the core training infrastructure:
// - MetaTrainer: Orchestrates hyperparameter optimization
// - SpecialistTrainer: Trains domain-specific experts
//
// All trainers use differentiable schedules for meta-learning.

pub mod meta;
pub mod specialist;

pub use meta::{MetaTrainer, MetaConfig, MetaLoss};
pub use specialist::{SpecialistTrainer, SpecialistConfig};

use simplex_std::dual::dual;
use simplex_std::{Clone, Default, Vec};
use crate::schedules::LearnedSchedules;

// =============================================================================
// Training Step Result
// =============================================================================

/// Result of a single training step
#[derive(Clone)]
pub struct StepResult {
    /// Training loss
    pub loss: dual,
    /// Validation loss (if computed)
    pub val_loss: Option<f64>,
    /// Current learning rate used
    pub lr: f64,
    /// Current step number
    pub step: u64,
    /// Gradient norm
    pub grad_norm: f64,
}

impl StepResult {
    pub fn new(loss: dual, step: u64, lr: f64) -> StepResult {
        StepResult {
            loss,
            val_loss: None,
            step,
            lr,
            grad_norm: 0.0,
        }
    }

    pub fn with_val_loss(mut self, val_loss: f64) -> StepResult {
        self.val_loss = Some(val_loss);
        self
    }

    pub fn with_grad_norm(mut self, norm: f64) -> StepResult {
        self.grad_norm = norm;
        self
    }
}

// =============================================================================
// Training History
// =============================================================================

/// History of training metrics for analysis
#[derive(Clone)]
pub struct TrainingHistory {
    /// Loss values per step
    pub losses: Vec<f64>,
    /// Learning rates per step
    pub lrs: Vec<f64>,
    /// Gradient norms per step
    pub grad_norms: Vec<f64>,
    /// Validation losses (sparse)
    pub val_losses: Vec<(u64, f64)>,
}

impl TrainingHistory {
    pub fn new() -> TrainingHistory {
        TrainingHistory {
            losses: Vec::new(),
            lrs: Vec::new(),
            grad_norms: Vec::new(),
            val_losses: Vec::new(),
        }
    }

    pub fn record(&mut self, result: &StepResult) {
        self.losses.push(result.loss.val);
        self.lrs.push(result.lr);
        self.grad_norms.push(result.grad_norm);
        if let Some(val) = result.val_loss {
            self.val_losses.push((result.step, val));
        }
    }

    /// Get recent loss values for plateau detection
    pub fn recent_losses(&self, n: usize) -> &[f64] {
        if self.losses.len() < n {
            &self.losses[..]
        } else {
            &self.losses[self.losses.len() - n..]
        }
    }

    /// Compute moving average of losses
    pub fn moving_average(&self, window: usize) -> f64 {
        let recent = self.recent_losses(window);
        if recent.len() == 0 {
            return 0.0;
        }
        var sum = 0.0;
        for l in recent {
            sum = sum + l;
        }
        sum / (recent.len() as f64)
    }

    /// Check if training has converged
    pub fn has_converged(&self, threshold: f64, patience: usize) -> bool {
        if self.losses.len() < patience * 2 {
            return false;
        }
        let old_avg = self.moving_average_at(self.losses.len() - patience, patience);
        let new_avg = self.moving_average(patience);
        (old_avg - new_avg).abs() < threshold
    }

    fn moving_average_at(&self, end: usize, window: usize) -> f64 {
        let start = if end > window { end - window } else { 0 };
        let slice = &self.losses[start..end];
        if slice.len() == 0 {
            return 0.0;
        }
        var sum = 0.0;
        for l in slice {
            sum = sum + l;
        }
        sum / (slice.len() as f64)
    }
}

impl Default for TrainingHistory {
    fn default() -> TrainingHistory {
        TrainingHistory::new()
    }
}

// =============================================================================
// Checkpoint
// =============================================================================

/// Training checkpoint for resumption
#[derive(Clone)]
pub struct Checkpoint {
    /// Current step
    pub step: u64,
    /// Current epoch
    pub epoch: u64,
    /// Best validation loss seen
    pub best_val_loss: f64,
    /// Step of best validation
    pub best_step: u64,
    /// Learned schedules state
    pub schedules: LearnedSchedules,
    /// Training history
    pub history: TrainingHistory,
}

impl Checkpoint {
    pub fn new() -> Checkpoint {
        Checkpoint {
            step: 0,
            epoch: 0,
            best_val_loss: f64::MAX,
            best_step: 0,
            schedules: LearnedSchedules::new(),
            history: TrainingHistory::new(),
        }
    }

    pub fn update_best(&mut self, val_loss: f64, step: u64) -> bool {
        if val_loss < self.best_val_loss {
            self.best_val_loss = val_loss;
            self.best_step = step;
            true
        } else {
            false
        }
    }

    /// Check if we should early stop
    pub fn should_early_stop(&self, patience: u64) -> bool {
        self.step > self.best_step + patience
    }
}

impl Default for Checkpoint {
    fn default() -> Checkpoint {
        Checkpoint::new()
    }
}

// =============================================================================
// Early Stopping
// =============================================================================

/// Early stopping configuration
#[derive(Clone)]
pub struct EarlyStopping {
    /// Patience in steps
    pub patience: u64,
    /// Minimum improvement to count
    pub min_delta: f64,
    /// Best loss seen
    best_loss: f64,
    /// Steps since improvement
    wait: u64,
}

impl EarlyStopping {
    pub fn new(patience: u64, min_delta: f64) -> EarlyStopping {
        EarlyStopping {
            patience,
            min_delta,
            best_loss: f64::MAX,
            wait: 0,
        }
    }

    /// Check if should stop, returns true if training should stop
    pub fn check(&mut self, loss: f64) -> bool {
        if loss < self.best_loss - self.min_delta {
            self.best_loss = loss;
            self.wait = 0;
            false
        } else {
            self.wait = self.wait + 1;
            self.wait >= self.patience
        }
    }

    pub fn reset(&mut self) {
        self.best_loss = f64::MAX;
        self.wait = 0;
    }
}

impl Default for EarlyStopping {
    fn default() -> EarlyStopping {
        EarlyStopping::new(10, 1e-4)
    }
}
