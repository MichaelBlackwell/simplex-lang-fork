// simplex-training::export::gguf - GGUF Format Exporter
//
// Implements GGUF (GPT-Generated Unified Format) export:
// - Compatible with llama.cpp and derivatives
// - Supports various quantization formats
// - Includes metadata and architecture info
//
// GGUF file format:
// 1. Magic number (GGUF)
// 2. Version (3)
// 3. Tensor count
// 4. Metadata KV pairs
// 5. Tensor info array
// 6. Alignment padding
// 7. Tensor data

use simplex_std::dual::dual;
use simplex_std::{Clone, Default, Vec, String};
use super::{ExportConfig, ExportTensor, ExportResult, TensorDtype};

// =============================================================================
// GGUF Constants
// =============================================================================

/// GGUF magic number: "GGUF" in little endian
const GGUF_MAGIC: u32 = 0x46554747;  // "GGUF"
/// GGUF format version
const GGUF_VERSION: u32 = 3;
/// Default alignment (32 bytes)
const GGUF_ALIGNMENT: u64 = 32;

// =============================================================================
// GGUF Value Types
// =============================================================================

/// GGUF metadata value type
#[derive(Clone, Copy)]
pub enum GgufValueType {
    /// Unsigned 8-bit
    U8 = 0,
    /// Signed 8-bit
    I8 = 1,
    /// Unsigned 16-bit
    U16 = 2,
    /// Signed 16-bit
    I16 = 3,
    /// Unsigned 32-bit
    U32 = 4,
    /// Signed 32-bit
    I32 = 5,
    /// Float 32-bit
    F32 = 6,
    /// Boolean
    Bool = 7,
    /// String
    String = 8,
    /// Array
    Array = 9,
    /// Unsigned 64-bit
    U64 = 10,
    /// Signed 64-bit
    I64 = 11,
    /// Float 64-bit
    F64 = 12,
}

// =============================================================================
// GGUF Metadata
// =============================================================================

/// GGUF metadata value
#[derive(Clone)]
pub enum GgufValue {
    U8(u8),
    I8(i8),
    U16(u16),
    I16(i16),
    U32(u32),
    I32(i32),
    F32(f32),
    Bool(bool),
    String(String),
    ArrayU32(Vec<u32>),
    ArrayI32(Vec<i32>),
    ArrayF32(Vec<f32>),
    U64(u64),
    I64(i64),
    F64(f64),
}

impl GgufValue {
    pub fn value_type(&self) -> GgufValueType {
        match self {
            GgufValue::U8(_) => GgufValueType::U8,
            GgufValue::I8(_) => GgufValueType::I8,
            GgufValue::U16(_) => GgufValueType::U16,
            GgufValue::I16(_) => GgufValueType::I16,
            GgufValue::U32(_) => GgufValueType::U32,
            GgufValue::I32(_) => GgufValueType::I32,
            GgufValue::F32(_) => GgufValueType::F32,
            GgufValue::Bool(_) => GgufValueType::Bool,
            GgufValue::String(_) => GgufValueType::String,
            GgufValue::ArrayU32(_) | GgufValue::ArrayI32(_) | GgufValue::ArrayF32(_) => GgufValueType::Array,
            GgufValue::U64(_) => GgufValueType::U64,
            GgufValue::I64(_) => GgufValueType::I64,
            GgufValue::F64(_) => GgufValueType::F64,
        }
    }

    /// Encode value to bytes
    pub fn encode(&self) -> Vec<u8> {
        var bytes = Vec::new();

        match self {
            GgufValue::U8(v) => bytes.push(*v),
            GgufValue::I8(v) => bytes.push(*v as u8),
            GgufValue::U16(v) => {
                bytes.push((*v & 0xFF) as u8);
                bytes.push(((*v >> 8) & 0xFF) as u8);
            }
            GgufValue::I16(v) => {
                let u = *v as u16;
                bytes.push((u & 0xFF) as u8);
                bytes.push(((u >> 8) & 0xFF) as u8);
            }
            GgufValue::U32(v) => {
                bytes.extend(u32_to_bytes(*v));
            }
            GgufValue::I32(v) => {
                bytes.extend(u32_to_bytes(*v as u32));
            }
            GgufValue::U64(v) => {
                bytes.extend(u64_to_bytes(*v));
            }
            GgufValue::I64(v) => {
                bytes.extend(u64_to_bytes(*v as u64));
            }
            GgufValue::F32(v) => {
                // Simplified float encoding
                bytes.extend(u32_to_bytes(f32_to_bits(*v)));
            }
            GgufValue::F64(v) => {
                bytes.extend(u64_to_bytes(f64_to_bits(*v)));
            }
            GgufValue::Bool(v) => bytes.push(if *v { 1 } else { 0 }),
            GgufValue::String(s) => {
                // Length prefix (u64) + string bytes
                bytes.extend(u64_to_bytes(s.len() as u64));
                for c in s.as_bytes() {
                    bytes.push(*c);
                }
            }
            GgufValue::ArrayU32(arr) => {
                // Array type (u32) + length (u64) + elements
                bytes.extend(u32_to_bytes(GgufValueType::U32 as u32));
                bytes.extend(u64_to_bytes(arr.len() as u64));
                for v in arr {
                    bytes.extend(u32_to_bytes(*v));
                }
            }
            GgufValue::ArrayI32(arr) => {
                bytes.extend(u32_to_bytes(GgufValueType::I32 as u32));
                bytes.extend(u64_to_bytes(arr.len() as u64));
                for v in arr {
                    bytes.extend(u32_to_bytes(*v as u32));
                }
            }
            GgufValue::ArrayF32(arr) => {
                bytes.extend(u32_to_bytes(GgufValueType::F32 as u32));
                bytes.extend(u64_to_bytes(arr.len() as u64));
                for v in arr {
                    bytes.extend(u32_to_bytes(f32_to_bits(*v)));
                }
            }
        }

        bytes
    }
}

/// GGUF metadata entry
#[derive(Clone)]
pub struct GgufMetadata {
    /// Key
    pub key: String,
    /// Value
    pub value: GgufValue,
}

impl GgufMetadata {
    pub fn new(key: &str, value: GgufValue) -> GgufMetadata {
        GgufMetadata {
            key: String::from(key),
            value,
        }
    }

    pub fn string(key: &str, value: &str) -> GgufMetadata {
        GgufMetadata::new(key, GgufValue::String(String::from(value)))
    }

    pub fn u32(key: &str, value: u32) -> GgufMetadata {
        GgufMetadata::new(key, GgufValue::U32(value))
    }

    pub fn u64(key: &str, value: u64) -> GgufMetadata {
        GgufMetadata::new(key, GgufValue::U64(value))
    }

    pub fn f32(key: &str, value: f32) -> GgufMetadata {
        GgufMetadata::new(key, GgufValue::F32(value))
    }

    /// Encode to bytes
    pub fn encode(&self) -> Vec<u8> {
        var bytes = Vec::new();

        // Key: length (u64) + string bytes
        bytes.extend(u64_to_bytes(self.key.len() as u64));
        for c in self.key.as_bytes() {
            bytes.push(*c);
        }

        // Value type
        bytes.extend(u32_to_bytes(self.value.value_type() as u32));

        // Value
        bytes.extend(self.value.encode());

        bytes
    }
}

// =============================================================================
// GGUF Tensor
// =============================================================================

/// GGUF tensor information
#[derive(Clone)]
pub struct GgufTensor {
    /// Tensor name
    pub name: String,
    /// Number of dimensions
    pub n_dims: u32,
    /// Shape (dimensions)
    pub shape: Vec<u64>,
    /// GGUF tensor type ID
    pub type_id: u32,
    /// Offset in data section
    pub offset: u64,
}

impl GgufTensor {
    pub fn new(name: &str, shape: Vec<u64>, dtype: TensorDtype) -> GgufTensor {
        GgufTensor {
            name: String::from(name),
            n_dims: shape.len() as u32,
            shape,
            type_id: dtype.gguf_type_id(),
            offset: 0,
        }
    }

    pub fn from_export_tensor(tensor: &ExportTensor) -> GgufTensor {
        GgufTensor {
            name: tensor.name.clone(),
            n_dims: tensor.shape.len() as u32,
            shape: tensor.shape.clone(),
            type_id: tensor.dtype.gguf_type_id(),
            offset: 0,
        }
    }

    /// Encode tensor info (not data) to bytes
    pub fn encode_info(&self) -> Vec<u8> {
        var bytes = Vec::new();

        // Name: length (u64) + string bytes
        bytes.extend(u64_to_bytes(self.name.len() as u64));
        for c in self.name.as_bytes() {
            bytes.push(*c);
        }

        // Number of dimensions
        bytes.extend(u32_to_bytes(self.n_dims));

        // Dimensions (as u64)
        for d in self.shape.iter() {
            bytes.extend(u64_to_bytes(*d));
        }

        // Type
        bytes.extend(u32_to_bytes(self.type_id));

        // Offset
        bytes.extend(u64_to_bytes(self.offset));

        bytes
    }
}

// =============================================================================
// GGUF Configuration
// =============================================================================

/// GGUF export configuration
#[derive(Clone)]
pub struct GgufConfig {
    /// General model name
    pub general_name: String,
    /// Architecture (e.g., "llama", "gpt2")
    pub architecture: String,
    /// Context length
    pub context_length: u32,
    /// Embedding dimension
    pub embedding_dim: u32,
    /// Number of attention heads
    pub n_heads: u32,
    /// Number of layers
    pub n_layers: u32,
    /// Vocabulary size
    pub vocab_size: u32,
    /// Data alignment
    pub alignment: u64,
    /// Quantization type
    pub quant_type: TensorDtype,
}

impl GgufConfig {
    pub fn new(name: &str, arch: &str) -> GgufConfig {
        GgufConfig {
            general_name: String::from(name),
            architecture: String::from(arch),
            context_length: 2048,
            embedding_dim: 4096,
            n_heads: 32,
            n_layers: 32,
            vocab_size: 32000,
            alignment: GGUF_ALIGNMENT,
            quant_type: TensorDtype::Q4_0,
        }
    }

    /// Configuration for small model
    pub fn small(name: &str) -> GgufConfig {
        var config = GgufConfig::new(name, "llama");
        config.embedding_dim = 2048;
        config.n_heads = 16;
        config.n_layers = 16;
        config
    }

    /// Configuration for medium model
    pub fn medium(name: &str) -> GgufConfig {
        var config = GgufConfig::new(name, "llama");
        config.embedding_dim = 4096;
        config.n_heads = 32;
        config.n_layers = 32;
        config
    }

    /// Configuration for large model
    pub fn large(name: &str) -> GgufConfig {
        var config = GgufConfig::new(name, "llama");
        config.embedding_dim = 8192;
        config.n_heads = 64;
        config.n_layers = 80;
        config
    }

    /// Generate standard metadata
    pub fn metadata(&self) -> Vec<GgufMetadata> {
        vec![
            GgufMetadata::string("general.name", &self.general_name),
            GgufMetadata::string("general.architecture", &self.architecture),
            GgufMetadata::u32(&format!("{}.context_length", self.architecture), self.context_length),
            GgufMetadata::u32(&format!("{}.embedding_length", self.architecture), self.embedding_dim),
            GgufMetadata::u32(&format!("{}.attention.head_count", self.architecture), self.n_heads),
            GgufMetadata::u32(&format!("{}.block_count", self.architecture), self.n_layers),
            GgufMetadata::u32("general.quantization_version", 2),
        ]
    }
}

impl Default for GgufConfig {
    fn default() -> GgufConfig {
        GgufConfig::new("simplex_model", "llama")
    }
}

// =============================================================================
// GGUF Exporter
// =============================================================================

/// GGUF file exporter
pub struct GgufExporter {
    /// Configuration
    pub config: GgufConfig,
    /// Metadata entries
    pub metadata: Vec<GgufMetadata>,
    /// Tensors
    pub tensors: Vec<GgufTensor>,
    /// Tensor data
    pub tensor_data: Vec<Vec<u8>>,
}

impl GgufExporter {
    /// Create new GGUF exporter
    pub fn new(config: GgufConfig) -> GgufExporter {
        let metadata = config.metadata();
        GgufExporter {
            config,
            metadata,
            tensors: Vec::new(),
            tensor_data: Vec::new(),
        }
    }

    /// Add metadata entry
    pub fn add_metadata(&mut self, meta: GgufMetadata) {
        self.metadata.push(meta);
    }

    /// Add tensor
    pub fn add_tensor(&mut self, tensor: ExportTensor) {
        let gguf_tensor = GgufTensor::from_export_tensor(&tensor);
        self.tensors.push(gguf_tensor);
        self.tensor_data.push(tensor.data);
    }

    /// Add tensor from dual values
    pub fn add_dual_tensor(&mut self, name: &str, shape: Vec<u64>, values: &[dual]) {
        let tensor = ExportTensor::from_dual(name, shape, values);
        self.add_tensor(tensor);
    }

    /// Compute alignment padding
    fn padding_bytes(current: u64, alignment: u64) -> Vec<u8> {
        let remainder = current % alignment;
        if remainder == 0 {
            Vec::new()
        } else {
            let padding = alignment - remainder;
            var bytes = Vec::new();
            for _ in 0..padding {
                bytes.push(0u8);
            }
            bytes
        }
    }

    /// Export to bytes
    pub fn export(&mut self) -> Vec<u8> {
        var bytes = Vec::new();

        // Header
        bytes.extend(u32_to_bytes(GGUF_MAGIC));
        bytes.extend(u32_to_bytes(GGUF_VERSION));
        bytes.extend(u64_to_bytes(self.tensors.len() as u64));
        bytes.extend(u64_to_bytes(self.metadata.len() as u64));

        // Metadata
        for meta in self.metadata.iter() {
            bytes.extend(meta.encode());
        }

        // Tensor info (update offsets as we go)
        var data_offset = 0u64;
        for i in 0..self.tensors.len() {
            // Align offset
            let alignment = self.config.alignment;
            let padding = if data_offset % alignment == 0 { 0 } else { alignment - (data_offset % alignment) };
            data_offset = data_offset + padding;

            self.tensors[i].offset = data_offset;
            bytes.extend(self.tensors[i].encode_info());

            data_offset = data_offset + (self.tensor_data[i].len() as u64);
        }

        // Alignment padding before data
        bytes.extend(Self::padding_bytes(bytes.len() as u64, self.config.alignment));

        // Tensor data
        for i in 0..self.tensor_data.len() {
            // Alignment padding
            bytes.extend(Self::padding_bytes(bytes.len() as u64, self.config.alignment));
            // Data
            bytes.extend(self.tensor_data[i].clone());
        }

        bytes
    }

    /// Get export result
    pub fn result(&self, output_path: &str) -> ExportResult {
        var total_params = 0u64;
        for t in self.tensors.iter() {
            var numel = 1u64;
            for d in t.shape.iter() {
                numel = numel * d;
            }
            total_params = total_params + numel;
        }

        ExportResult {
            output_path: String::from(output_path),
            file_size: 0,  // Would be set after writing
            tensor_count: self.tensors.len() as u64,
            total_params,
            compression_ratio: 1.0,
            duration_ms: 0,
        }
    }
}

impl Default for GgufExporter {
    fn default() -> GgufExporter {
        GgufExporter::new(GgufConfig::default())
    }
}

impl GgufExporter {
    /// Export a merged model to a GGUF file
    ///
    /// Takes a MergedModel containing merged weight tensors and writes
    /// a complete GGUF file to the specified path.
    pub fn export_model(&self, model: &super::super::lora::adapter::MergedModel, path: &str) -> Result<(), String> {
        use simplex_std::fs;

        // Create a new exporter with the same config
        var exporter = GgufExporter::new(self.config.clone());

        // Add tensors from the merged model
        for (name, tensor) in model.weights.iter() {
            // Convert DualTensor to ExportTensor
            let shape: Vec<u64> = tensor.shape().dims().iter()
                .map(|&d| d as u64)
                .collect();

            let values: Vec<f64> = tensor.data().iter()
                .map(|d| d.val)
                .collect();

            // Create export tensor with appropriate dtype based on quantization
            let export_tensor = ExportTensor::from_f64(name, shape.clone(), &values);
            exporter.add_tensor(export_tensor);
        }

        // Add model-specific metadata
        exporter.add_metadata(GgufMetadata::string(
            "simplex.lora.rank",
            &model.config.rank.to_string()
        ));
        exporter.add_metadata(GgufMetadata::f32(
            "simplex.lora.alpha",
            model.config.alpha as f32
        ));

        // Export to bytes
        let bytes = exporter.export();

        // Write to file
        fs::write(path, &bytes).map_err(|e| format!("Failed to write GGUF file: {}", e))?;

        Ok(())
    }

    /// Export model to bytes without writing to file
    pub fn export_model_bytes(&self, model: &super::super::lora::adapter::MergedModel) -> Vec<u8> {
        var exporter = GgufExporter::new(self.config.clone());

        for (name, tensor) in model.weights.iter() {
            let shape: Vec<u64> = tensor.shape().dims().iter()
                .map(|&d| d as u64)
                .collect();

            let values: Vec<f64> = tensor.data().iter()
                .map(|d| d.val)
                .collect();

            let export_tensor = ExportTensor::from_f64(name, shape, &values);
            exporter.add_tensor(export_tensor);
        }

        exporter.export()
    }
}

// =============================================================================
// Helper Functions
// =============================================================================

fn u32_to_bytes(val: u32) -> Vec<u8> {
    vec![
        (val & 0xFF) as u8,
        ((val >> 8) & 0xFF) as u8,
        ((val >> 16) & 0xFF) as u8,
        ((val >> 24) & 0xFF) as u8,
    ]
}

fn u64_to_bytes(val: u64) -> Vec<u8> {
    vec![
        (val & 0xFF) as u8,
        ((val >> 8) & 0xFF) as u8,
        ((val >> 16) & 0xFF) as u8,
        ((val >> 24) & 0xFF) as u8,
        ((val >> 32) & 0xFF) as u8,
        ((val >> 40) & 0xFF) as u8,
        ((val >> 48) & 0xFF) as u8,
        ((val >> 56) & 0xFF) as u8,
    ]
}

fn f32_to_bits(f: f32) -> u32 {
    if f == 0.0 {
        return 0;
    }

    let sign = if f < 0.0 { 1u32 } else { 0u32 };
    let abs_f = if f < 0.0 { -f } else { f };

    var exponent: i32 = 127;
    var mantissa = abs_f;

    while mantissa >= 2.0 {
        mantissa = mantissa / 2.0;
        exponent = exponent + 1;
    }
    while mantissa < 1.0 && exponent > 0 {
        mantissa = mantissa * 2.0;
        exponent = exponent - 1;
    }

    mantissa = mantissa - 1.0;
    let mantissa_bits = (mantissa * 8388608.0) as u32;

    (sign << 31) | ((exponent as u32) << 23) | mantissa_bits
}

fn f64_to_bits(f: f64) -> u64 {
    if f == 0.0 {
        return 0;
    }

    let sign = if f < 0.0 { 1u64 } else { 0u64 };
    let abs_f = if f < 0.0 { -f } else { f };

    var exponent: i64 = 1023;
    var mantissa = abs_f;

    while mantissa >= 2.0 {
        mantissa = mantissa / 2.0;
        exponent = exponent + 1;
    }
    while mantissa < 1.0 && exponent > 0 {
        mantissa = mantissa * 2.0;
        exponent = exponent - 1;
    }

    mantissa = mantissa - 1.0;
    let mantissa_bits = (mantissa * 4503599627370496.0) as u64;  // 2^52

    (sign << 63) | ((exponent as u64) << 52) | mantissa_bits
}
