// simplex-training::schedules::quant - Learnable Quantization Schedule
//
// Implements differentiable quantization with:
// - Learnable bit-width schedule
// - Per-layer precision
// - Quantization-aware training noise
// - Straight-through estimator (STE)

use simplex_std::dual::dual;
use simplex_std::{Clone, Default, Vec};

/// Gradient for quantization parameters
#[derive(Clone)]
pub struct QuantGradient {
    pub d_initial_bits: f64,
    pub d_final_bits: f64,
    pub d_quant_rate: f64,
    pub d_noise_scale: f64,
    pub d_ste_slope: f64,
}

impl QuantGradient {
    pub fn scale(&mut self, factor: f64) {
        self.d_initial_bits = self.d_initial_bits * factor;
        self.d_final_bits = self.d_final_bits * factor;
        self.d_quant_rate = self.d_quant_rate * factor;
        self.d_noise_scale = self.d_noise_scale * factor;
        self.d_ste_slope = self.d_ste_slope * factor;
    }

    pub fn norm(&self) -> f64 {
        (self.d_initial_bits * self.d_initial_bits +
         self.d_final_bits * self.d_final_bits +
         self.d_quant_rate * self.d_quant_rate +
         self.d_noise_scale * self.d_noise_scale +
         self.d_ste_slope * self.d_ste_slope).sqrt()
    }
}

impl Default for QuantGradient {
    fn default() -> QuantGradient {
        QuantGradient {
            d_initial_bits: 0.0,
            d_final_bits: 0.0,
            d_quant_rate: 0.0,
            d_noise_scale: 0.0,
            d_ste_slope: 0.0,
        }
    }
}

/// Learnable quantization schedule
#[derive(Clone)]
pub struct LearnableQuantization {
    /// Starting precision (bits)
    pub initial_bits: dual,
    /// Target precision (bits)
    pub final_bits: dual,
    /// Rate of precision reduction
    pub quant_rate: dual,
    /// Noise scale during training
    pub noise_scale: dual,
    /// STE gradient slope
    pub ste_slope: dual,
}

impl LearnableQuantization {
    /// Create with default values
    pub fn new() -> LearnableQuantization {
        LearnableQuantization {
            initial_bits: dual::constant(16.0),  // Start at fp16
            final_bits: dual::variable(4.0),     // Target int4
            quant_rate: dual::variable(0.0001),
            noise_scale: dual::variable(0.1),
            ste_slope: dual::variable(1.0),
        }
    }

    /// Get current effective bit-width at step
    pub fn current_bits(&self, step: dual) -> dual {
        let progress = dual::constant(1.0) - (dual::zero() - self.quant_rate * step).exp();
        self.initial_bits - (self.initial_bits - self.final_bits) * progress
    }

    /// Quantize value to given bits (differentiable via STE)
    ///
    /// Uses straight-through estimator: forward = quantized, backward = identity
    pub fn quantize_value(&self, x: dual, step: dual) -> dual {
        let bits = self.current_bits(step);

        // Compute scale: how many levels
        let levels = dual::constant(2.0).pow(bits) - dual::constant(1.0);

        // Clamp to [-1, 1] range (assuming normalized)
        let clamped = x.clamp(-1.0, 1.0);

        // Scale to [0, levels]
        let scaled = (clamped + dual::constant(1.0)) / dual::constant(2.0) * levels;

        // Round (forward only - STE keeps gradient)
        let rounded_val = scaled.val.round();
        let rounded = dual::new(rounded_val, scaled.der * self.ste_slope.val);

        // Scale back to [-1, 1]
        let unscaled = rounded / levels * dual::constant(2.0) - dual::constant(1.0);

        unscaled
    }

    /// Add quantization-aware training noise
    ///
    /// Noise helps model prepare for quantization error
    pub fn add_qat_noise(&self, x: dual, step: dual) -> dual {
        let bits = self.current_bits(step);
        let quantization_step = dual::constant(2.0) / (dual::constant(2.0).pow(bits) - dual::constant(1.0));

        // Add uniform noise proportional to quantization step
        let noise_range = quantization_step * self.noise_scale;

        // Note: In practice, we'd sample random noise here
        // For differentiability, we use deterministic approximation
        x + noise_range * dual::constant(0.5)  // Mean noise
    }

    /// Quantize a tensor of values
    pub fn quantize_tensor(&self, tensor: &[dual], step: dual) -> Vec<dual> {
        var result = Vec::new();
        for x in tensor {
            result.push(self.quantize_value(*x, step));
        }
        result
    }

    /// Extract gradients
    pub fn gradient(&self) -> QuantGradient {
        QuantGradient {
            d_initial_bits: self.initial_bits.der,
            d_final_bits: self.final_bits.der,
            d_quant_rate: self.quant_rate.der,
            d_noise_scale: self.noise_scale.der,
            d_ste_slope: self.ste_slope.der,
        }
    }

    /// Update parameters
    pub fn update(&mut self, grad: &QuantGradient, lr: f64) {
        self.final_bits = dual::new(
            self.final_bits.val - lr * grad.d_final_bits,
            1.0
        );
        self.quant_rate = dual::new(
            self.quant_rate.val - lr * grad.d_quant_rate,
            1.0
        );
        self.noise_scale = dual::new(
            self.noise_scale.val - lr * grad.d_noise_scale,
            1.0
        );
        self.ste_slope = dual::new(
            self.ste_slope.val - lr * grad.d_ste_slope,
            1.0
        );

        // Clamp to valid ranges
        if self.final_bits.val < 2.0 {
            self.final_bits = dual::new(2.0, self.final_bits.der);
        }
        if self.final_bits.val > 16.0 {
            self.final_bits = dual::new(16.0, self.final_bits.der);
        }
        if self.noise_scale.val < 0.0 {
            self.noise_scale = dual::new(0.0, self.noise_scale.der);
        }
        if self.ste_slope.val < 0.1 {
            self.ste_slope = dual::new(0.1, self.ste_slope.der);
        }
    }

    /// L2 norm for regularization
    pub fn l2_norm(&self) -> dual {
        self.final_bits * self.final_bits +
        self.quant_rate * self.quant_rate +
        self.noise_scale * self.noise_scale
    }
}

impl Default for LearnableQuantization {
    fn default() -> LearnableQuantization {
        LearnableQuantization::new()
    }
}
