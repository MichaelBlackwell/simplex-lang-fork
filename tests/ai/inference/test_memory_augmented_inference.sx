// Test file for Memory-Augmented Inference
// v0.5.0: Context flows from Anima -> HiveMnemonic -> SLM

// External declarations for memory-augmented inference
fn slm_config_new() -> i64;
fn slm_config_set_model(cfg: i64, model: i64);
fn slm_config_set_context_size(cfg: i64, size: i64);
fn slm_config_set_temperature(cfg: i64, temp: i64);
fn slm_config_set_threads(cfg: i64, threads: i64);
fn slm_config_close(cfg: i64);

fn slm_load(config: i64) -> i64;
fn slm_unload(handle: i64);

fn memory_augmented_slm_new(slm: i64, context_budget: i64) -> i64;
fn memory_augmented_slm_set_episodic(maslm: i64, context: i64);
fn memory_augmented_slm_set_semantic(maslm: i64, context: i64);
fn memory_augmented_slm_set_beliefs(maslm: i64, context: i64);
fn memory_augmented_slm_get_full_context(maslm: i64) -> i64;
fn memory_augmented_slm_infer(maslm: i64, prompt: i64) -> i64;
fn memory_augmented_slm_close(maslm: i64);

fn anima_memory_new(capacity: i64) -> i64;
fn anima_remember(mem: i64, content: i64, importance: f64) -> i64;
fn anima_learn(mem: i64, content: i64, confidence: f64, source: i64) -> i64;
fn anima_believe(mem: i64, content: i64, confidence: f64, evidence: i64) -> i64;
fn anima_format_context(mem: i64) -> i64;
fn anima_memory_close(mem: i64);

fn hive_mnemonic_new(episodic_cap: i64, semantic_cap: i64, belief_threshold: i64) -> i64;
fn hive_mnemonic_learn(mnemonic: i64, content: i64, confidence: f64) -> i64;
fn hive_mnemonic_remember(mnemonic: i64, content: i64, importance: f64) -> i64;
fn hive_mnemonic_format_context(mnemonic: i64, hive_name: i64) -> i64;
fn hive_mnemonic_close(mnemonic: i64);

fn context_builder_new() -> i64;
fn context_builder_add_anima(builder: i64, anima_context: i64);
fn context_builder_add_mnemonic(builder: i64, mnemonic_context: i64);
fn context_builder_add_prompt(builder: i64, prompt: i64);
fn context_builder_build(builder: i64) -> i64;
fn context_builder_token_count(builder: i64) -> i64;
fn context_builder_close(builder: i64);

fn inference_request_new(slm: i64) -> i64;
fn inference_request_set_anima(req: i64, anima: i64);
fn inference_request_set_mnemonic(req: i64, mnemonic: i64, hive_name: i64);
fn inference_request_set_prompt(req: i64, prompt: i64);
fn inference_request_execute(req: i64) -> i64;
fn inference_request_get_full_prompt(req: i64) -> i64;
fn inference_request_close(req: i64);

fn string_from(s: i64) -> i64;
fn string_len(s: i64) -> i64;
fn string_contains(s: i64, substr: i64) -> i64;
fn print(s: i64);
fn println(s: i64);
fn print_i64(n: i64);
fn print_string(s: i64);

fn main() {
    println("=== Memory-Augmented Inference Test ===");
    println("v0.5.0: Anima -> HiveMnemonic -> SLM Context Flow");
    println("");

    // Test 1: Create SLM config
    println("--- Test 1: SLM Configuration ---");
    let config: i64 = slm_config_new();
    slm_config_set_model(config, string_from("simplex-cognitive-7b"));
    slm_config_set_context_size(config, 4096);
    slm_config_set_temperature(config, 70);  // 0.7
    slm_config_set_threads(config, 4);

    println("Created SLM config:");
    println("  Model: simplex-cognitive-7b");
    println("  Context: 4096 tokens");
    println("  Temperature: 0.7");
    println("  Threads: 4");
    println("PASS: SLM config created");
    println("");

    // Test 2: Create Memory-Augmented SLM
    println("--- Test 2: Memory-Augmented SLM ---");
    // Note: In real test, this would load actual model
    // For unit test, we use a mock/stub handle
    let slm_handle: i64 = 12345;  // Mock handle
    let maslm: i64 = memory_augmented_slm_new(slm_handle, 2048);  // 2048 token budget for memory

    if maslm != 0 {
        println("PASS: Created memory-augmented SLM");
        print("  Context budget: 2048 tokens");
        println("");
    } else {
        println("FAIL: Could not create memory-augmented SLM");
    }
    println("");

    // Test 3: Set memory contexts
    println("--- Test 3: Set Memory Contexts ---");
    let episodic: i64 = string_from("Recent experiences:\n- Analyzed security code yesterday\n- Found null pointer bug in auth.sx");
    let semantic: i64 = string_from("Known facts:\n- This codebase uses clean architecture\n- Team prefers explicit error handling");
    let beliefs: i64 = string_from("Current beliefs:\n- User prefers detailed output (85%)");

    memory_augmented_slm_set_episodic(maslm, episodic);
    memory_augmented_slm_set_semantic(maslm, semantic);
    memory_augmented_slm_set_beliefs(maslm, beliefs);

    println("Set all memory contexts:");
    println("  Episodic: 2 experiences");
    println("  Semantic: 2 facts");
    println("  Beliefs: 1 belief");
    println("PASS: Memory contexts set");
    println("");

    // Test 4: Get full context
    println("--- Test 4: Get Full Context ---");
    let full_context: i64 = memory_augmented_slm_get_full_context(maslm);
    if full_context != 0 {
        println("Full context for SLM:");
        println("---");
        print_string(full_context);
        println("");
        println("---");

        // Verify structure
        if string_contains(full_context, string_from("<context>")) == 1 {
            println("PASS: Contains <context> tag");
        }
        if string_contains(full_context, string_from("Recent experiences")) == 1 {
            println("PASS: Contains episodic section");
        }
        if string_contains(full_context, string_from("Known facts")) == 1 {
            println("PASS: Contains semantic section");
        }
        if string_contains(full_context, string_from("Current beliefs")) == 1 {
            println("PASS: Contains beliefs section");
        }
    } else {
        println("FAIL: Could not get full context");
    }
    println("");

    // Test 5: Create real Anima and format its context
    println("--- Test 5: Anima Context Formatting ---");
    let anima: i64 = anima_memory_new(7);  // Working memory capacity 7

    // Add some memories
    anima_remember(anima, string_from("User asked about error handling"), 0.8);
    anima_remember(anima, string_from("Helped debug null pointer"), 0.9);
    anima_learn(anima, string_from("Simplex uses actors for concurrency"), 0.95, string_from("docs"));
    anima_believe(anima, string_from("User prefers verbose output"), 0.7, string_from("observation"));

    let anima_context: i64 = anima_format_context(anima);
    if anima_context != 0 {
        println("Anima formatted context:");
        println("---");
        print_string(anima_context);
        println("");
        println("---");
        println("PASS: Anima context formatted");
    } else {
        println("FAIL: Could not format anima context");
    }
    println("");

    // Test 6: Create HiveMnemonic and format its context
    println("--- Test 6: HiveMnemonic Context Formatting ---");
    let mnemonic: i64 = hive_mnemonic_new(100, 500, 50);

    // Add shared knowledge
    hive_mnemonic_learn(mnemonic, string_from("Production uses PostgreSQL 15"), 0.95);
    hive_mnemonic_remember(mnemonic, string_from("Team completed security audit last week"), 0.9);

    let mnemonic_context: i64 = hive_mnemonic_format_context(mnemonic, string_from("AnalyticsHive"));
    if mnemonic_context != 0 {
        println("HiveMnemonic formatted context:");
        println("---");
        print_string(mnemonic_context);
        println("");
        println("---");

        if string_contains(mnemonic_context, string_from("<hive name=\"AnalyticsHive\">")) == 1 {
            println("PASS: Contains hive name tag");
        }
        println("PASS: HiveMnemonic context formatted");
    } else {
        println("FAIL: Could not format mnemonic context");
    }
    println("");

    // Test 7: Context Builder
    println("--- Test 7: Context Builder ---");
    let builder: i64 = context_builder_new();

    context_builder_add_anima(builder, anima_context);
    context_builder_add_mnemonic(builder, mnemonic_context);
    context_builder_add_prompt(builder, string_from("What are the best practices for error handling?"));

    let combined: i64 = context_builder_build(builder);
    let token_count: i64 = context_builder_token_count(builder);

    if combined != 0 {
        println("Combined context:");
        println("---");
        print_string(combined);
        println("");
        println("---");
        print("Estimated tokens: ");
        print_i64(token_count);
        println("");
        println("PASS: Context builder works");
    } else {
        println("FAIL: Context builder failed");
    }

    context_builder_close(builder);
    println("");

    // Test 8: Inference Request with full context
    println("--- Test 8: Inference Request ---");
    let req: i64 = inference_request_new(slm_handle);

    inference_request_set_anima(req, anima);
    inference_request_set_mnemonic(req, mnemonic, string_from("TestHive"));
    inference_request_set_prompt(req, string_from("Analyze this code for issues."));

    let full_prompt: i64 = inference_request_get_full_prompt(req);
    if full_prompt != 0 {
        println("Full inference prompt:");
        println("---");
        print_string(full_prompt);
        println("");
        println("---");

        // Verify all components are present
        let has_anima: i64 = string_contains(full_prompt, string_from("<context>"));
        let has_hive: i64 = string_contains(full_prompt, string_from("<hive"));
        let has_prompt: i64 = string_contains(full_prompt, string_from("Analyze this code"));

        if has_anima == 1 && has_hive == 1 && has_prompt == 1 {
            println("PASS: Full prompt contains anima, hive, and user prompt");
        } else {
            println("FAIL: Missing components in full prompt");
        }
    } else {
        println("FAIL: Could not build full prompt");
    }

    inference_request_close(req);
    println("");

    // Test 9: Context truncation
    println("--- Test 9: Context Truncation ---");
    // Create a very large context that exceeds budget
    let large_anima: i64 = anima_memory_new(100);
    let i: i64 = 0;
    while i < 50 {
        anima_remember(large_anima, string_from("This is a very long memory entry that takes up tokens"), 0.5);
        i = i + 1;
    }

    let large_context: i64 = anima_format_context(large_anima);
    let large_len: i64 = string_len(large_context);
    print("Large context length: ");
    print_i64(large_len);
    println(" characters");

    // Memory-augmented SLM should truncate if needed
    memory_augmented_slm_set_episodic(maslm, large_context);
    let truncated: i64 = memory_augmented_slm_get_full_context(maslm);
    let truncated_len: i64 = string_len(truncated);
    print("After augmentation: ");
    print_i64(truncated_len);
    println(" characters");

    println("PASS: Context truncation handled");
    anima_memory_close(large_anima);
    println("");

    // Test 10: Empty context handling
    println("--- Test 10: Empty Context Handling ---");
    let empty_maslm: i64 = memory_augmented_slm_new(slm_handle, 2048);
    // Don't set any contexts

    let empty_context: i64 = memory_augmented_slm_get_full_context(empty_maslm);
    if empty_context != 0 {
        print("Empty MASLM context length: ");
        print_i64(string_len(empty_context));
        println("");
        println("PASS: Empty context handled gracefully");
    } else {
        println("PASS: Returns null for empty context");
    }
    memory_augmented_slm_close(empty_maslm);
    println("");

    // Test 11: Belief threshold filtering
    println("--- Test 11: Belief Threshold Filtering ---");
    let filtered_anima: i64 = anima_memory_new(7);
    anima_believe(filtered_anima, string_from("High confidence belief"), 0.9, 0);
    anima_believe(filtered_anima, string_from("Medium confidence belief"), 0.5, 0);
    anima_believe(filtered_anima, string_from("Low confidence belief"), 0.2, 0);  // Below 30%

    let filtered_context: i64 = anima_format_context(filtered_anima);

    // With 30% threshold, low confidence should be excluded
    if string_contains(filtered_context, string_from("High confidence")) == 1 {
        println("PASS: High confidence belief included");
    }
    if string_contains(filtered_context, string_from("Low confidence")) == 0 {
        println("PASS: Low confidence belief excluded (below threshold)");
    }

    anima_memory_close(filtered_anima);
    println("");

    // Test 12: Context priority order
    println("--- Test 12: Context Priority Order ---");
    // Anima context should appear BEFORE hive mnemonic
    // Both should appear BEFORE the user prompt
    let builder2: i64 = context_builder_new();
    context_builder_add_anima(builder2, string_from("ANIMA_MARKER"));
    context_builder_add_mnemonic(builder2, string_from("MNEMONIC_MARKER"));
    context_builder_add_prompt(builder2, string_from("USER_PROMPT_MARKER"));

    let ordered: i64 = context_builder_build(builder2);

    // Find positions
    // In correct order: ANIMA < MNEMONIC < USER_PROMPT
    println("Checking context order...");
    if string_contains(ordered, string_from("ANIMA_MARKER")) == 1 {
        println("  ANIMA_MARKER found");
    }
    if string_contains(ordered, string_from("MNEMONIC_MARKER")) == 1 {
        println("  MNEMONIC_MARKER found");
    }
    if string_contains(ordered, string_from("USER_PROMPT_MARKER")) == 1 {
        println("  USER_PROMPT_MARKER found");
    }
    println("PASS: All markers present in context");

    context_builder_close(builder2);

    // Cleanup
    hive_mnemonic_close(mnemonic);
    anima_memory_close(anima);
    memory_augmented_slm_close(maslm);
    slm_config_close(config);

    println("");
    println("=== Memory-Augmented Inference Test Complete! ===");
}
